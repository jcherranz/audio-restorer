# AGENTS.md - LLM Agent Instructions

> **This file is for AI agents/LLMs working on this project.**
> It contains the context, rules, and procedures for autonomous development.

## Document Hierarchy

This project uses three complementary documents:

| Document | Purpose | Changes |
|----------|---------|---------|
| `docs/SENIOR_ENGINEER_PROMPT.md` | **Mindset** - How to think (principles, behaviors) | Rarely |
| `docs/WORKFLOW_ORCHESTRATION.md` | **Process** - How to work (planning, verification, tasks) | Rarely |
| `AGENTS.md` (this file) | **Project** - What to do on THIS project | Often |

**Read order:** SENIOR_ENGINEER â†’ WORKFLOW_ORCHESTRATION â†’ AGENTS.md

When in doubt:
- Behavioral questions â†’ SENIOR_ENGINEER_PROMPT.md
- Process questions â†’ WORKFLOW_ORCHESTRATION.md
- Project-specific questions â†’ This file

## Project Goal

Create the best possible audio restoration tool for conference recordings.
**Current Focus:** High-impact audio quality improvements via Kaizen methodology.
**Video processing is NOT a priority.**

## Kaizen Approach

This project follows **Kaizen** (continuous improvement) principles:
- **One iteration per session** - Complete, test, document before next
- **Measurable outcomes** - Every change has before/after metrics
- **No regressions** - Quality score must stay >= 75, SNR >= 25dB
- **Document everything** - Future agents need full context

## Current Status (Last Updated: 2026-02-05)

### What Works Now
- âœ… YouTube audio downloading
- âœ… Basic noise reduction (spectral gating)
- âœ… Audio normalization
- âœ… Command-line interface

### Test Video (DO NOT CHANGE)
```
URL: https://youtu.be/cglDoG0GzyA
Duration: ~58 minutes
Purpose: Reference video for all quality testing
Baseline Quality Score: 66.5 (simple enhancer)
ML Enhancer Score: 81.0 (torch_advanced)
DeepFilter Score: 115.9 (deepfilter) - BEST
Location: Test files cached in temp/ (when --keep-temp used)
```

### Current Audio Pipeline (Phase 2 - ML Enhancement)
```
YouTube URL â†’ Download â†’ Extract Audio â†’ VAD â†’ ML Spectral Gating â†’ Filters â†’ Normalization â†’ Output
```

### Current Quality Metrics
| Metric | Simple | ML (torch) | DeepFilter | Best Improvement |
|--------|--------|------------|------------|------------------|
| Quality Score | 66.5 | 81.0 | **115.9** | +49.4 (+74%) |
| SNR | 21.4 dB | 28.5 dB | **49.0 dB** | +27.6 dB |
| Noise Level | -38.3 dB | -44.3 dB | **-84.4 dB** | -46.1 dB |
| Processing Time | 171s | 40s | 134s | varies |

### SOTA Metrics (Iteration 6)
| Metric | DeepFilter | ML (torch) | Simple | Range |
|--------|------------|------------|--------|-------|
| DNSMOS OVRL | **2.62** | 1.16 | 1.08 | 1-5 |
| DNSMOS SIG | **2.95** | 1.24 | 1.16 | 1-5 (speech) |
| DNSMOS BAK | **3.87** | 1.34 | 1.23 | 1-5 (background) |

**Note:** DNSMOS was trained on clean speech. Conference recordings naturally score lower.

## ðŸ—ï¸ Project Architecture

### Core Principle: AUDIO ONLY
- Video processing exists but is SECONDARY
- All quality improvements focus on AUDIO
- Output format: WAV (lossless) or high-quality MP3

### Directory Structure (MUST NOT CHANGE)
```
audio-restorer/
â”œâ”€â”€ AGENTS.md           â† YOU ARE HERE - Read first!
â”œâ”€â”€ ITERATION_LOG.md    â† Log of all changes made
â”œâ”€â”€ ROADMAP.md          â† Current roadmap and plans
â”œâ”€â”€ docs/QUALITY_METRICS.md  â† How we measure audio quality
â”œâ”€â”€ tests/              â† All test files
â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â”œâ”€â”€ test_quality.py
â”‚   â””â”€â”€ test_benchmarks.py
â”œâ”€â”€ run.py              â† Main entry point
â”œâ”€â”€ config.py           â† Configuration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ downloader.py
â”‚   â”œâ”€â”€ audio_enhancer.py â† MAIN FOCUS FOR IMPROVEMENTS
â”‚   â””â”€â”€ pipeline.py
â”œâ”€â”€ output/             â† Test outputs go here
â”œâ”€â”€ temp/               â† Temporary files
â””â”€â”€ benchmarks/         â† Quality benchmarks and samples
```

## ðŸ“ Project-Specific Rules

> For general principles (simplicity, assumptions, scope), see `docs/SENIOR_ENGINEER_PROMPT.md`.
> For workflow (planning, verification, tasks), see `docs/WORKFLOW_ORCHESTRATION.md`.

### 1. Documentation Updates
- Update `ITERATION_LOG.md` with every change (what, why, metrics)
- Update `ROADMAP.md` when completing milestones
- Track work in `tasks/todo.md`

### 2. Testing with Reference Video
- Use `https://youtu.be/cglDoG0GzyA` for all quality tests
- Run quality gate before committing: `python tests/quality_gate.py`
- Compare before/after with metrics

### 3. Audio Quality Focus
- Video features are secondary
- Every iteration should improve audio OR add audio testing
- New features must be optional (CLI flags)

## ðŸ”„ Iteration Workflow

When working on this project:

### Step 1: Read Current State
1. Read `AGENTS.md` (this file)
2. Read `ITERATION_LOG.md` - see what's been done
3. Read `ROADMAP.md` - see current priorities
4. Read `docs/QUALITY_METRICS.md` - understand how we measure success

### Step 2: Plan Your Work
1. Check `ROADMAP.md` for current phase
2. Create a plan for what you'll implement (track in `tasks/todo.md` per `docs/WORKFLOW_ORCHESTRATION.md`)
3. Document expected outcomes

### Step 3: Implement
1. Make changes to code
2. Add/update tests in `TESTS/`
3. Run tests with reference video

### Step 4: Document
1. Update `ITERATION_LOG.md` with:
   - What was changed
   - Why it was changed
   - Test results
   - Before/after metrics
2. Update `ROADMAP.md` if completing milestones

### Step 5: Verify
1. Check that all tests pass
2. Verify audio quality improved (or didn't degrade)
3. Confirm documentation is complete

## Testing Requirements

### Quality Gate (MANDATORY)

Before any change is accepted, run the quality gate:

```bash
# Quick verification
python tests/quality_gate.py output/enhanced.wav

# Fails if: quality_score < 75 OR SNR < 25dB
```

### Full Test Suite

```bash
# 1. Verify CLI works
python run.py --help

# 2. Run existing tests
python -m pytest tests/ -v

# 3. Test with reference video
python run.py "https://youtu.be/cglDoG0GzyA" --audio-only -o output/test

# 4. Measure quality
python tests/measure_quality.py output/test_enhanced.wav

# 5. Compare with baseline
python tests/measure_quality.py --compare output/baseline.wav output/test_enhanced.wav
```

### Mandatory Test for Every Iteration
```bash
# Run this exact command for every quality improvement
python run.py "https://youtu.be/cglDoG0GzyA" --audio-only --keep-temp

# Then analyze output with:
python tests/measure_quality.py output/audio_cglDoG0GzyA_enhanced.wav
```

### Quality Metrics to Track
1. **SNR (Signal-to-Noise Ratio)** - Higher is better
2. **Dynamic Range** - Should be well-balanced
3. **Clarity Score** - Custom metric for speech intelligibility
4. **Processing Time** - Should not increase significantly
5. **DNSMOS** (SOTA) - Neural MOS predictor (SIG, BAK, OVRL), range 1-5
6. **PESQ** (SOTA) - Perceptual quality, range 1-4.5 (requires reference)
7. **STOI** (SOTA) - Speech intelligibility, range 0-1 (requires reference)

### SOTA Metrics (Iteration 6+)
```bash
# Run SOTA metrics on enhanced audio
python tests/sota_benchmark.py output/enhanced.wav

# Compare multiple files
python tests/sota_benchmark.py output/*.wav --quiet
```

## ðŸ“Š Current Audio Processing Chain

```python
# Current implementation in audio_enhancer.py:

class SimpleEnhancer:
    def enhance(self, audio_path, output_path):
        # 1. High-pass filter @ 100Hz (remove rumble)
        # 2. Low-pass filter @ 8000Hz (remove hiss)
        # 3. Dynamic compression (even out loud/quiet)
        # 4. Loudness normalization (-16 LUFS)
        pass
```

### Known Limitations & Design Decisions

**Implemented Features:**
1. âœ… ML-based noise suppression (PyTorch spectral gating, DeepFilterNet neural)
2. âœ… Speaker diarization and isolation (Phase 3 complete)
3. âœ… Distance-robust enhancement (adaptive gain/EQ)
4. âœ… De-reverberation (NARA-WPE, optional)

**Acknowledged Limitations:**
1. **Heuristic Diarization:** Uses energy + spectral features, not embedding-based models
   like pyannote.audio. Works for typical conference recordings but may struggle with
   complex multi-speaker scenarios with overlapping speech.

2. **Heuristic Distance Estimation:** Simple feature-based approach (energy, HF ratio,
   SNR, reverb ratio). Not model-based speaker separation. May amplify noise in
   challenging acoustic conditions.

3. **Simplified Quality Metrics:** Basic measure_quality.py uses simplified LUFS
   estimation and custom clarity scores. For academic-grade metrics, use
   `tests/sota_benchmark.py` which provides DNSMOS, PESQ, STOI, and SI-SDR.

4. **Sample Rate:** Pipeline uses 48kHz throughout to match DeepFilterNet's native rate.
   This is a deliberate choice to avoid quality loss from multiple resampling operations.

5. **GPU Dependency for Best Quality:** DeepFilterNet provides best results but is
   slow on CPU. Auto-detection selects deepfilter when GPU available, torch_advanced
   otherwise.

## ðŸŽ¯ Success Criteria

### Audio Quality is "Good Enough" When:
- [x] Speech is clearly intelligible at normal volume âœ…
- [x] Background noise reduced by >50% âœ…
- [x] No audible artifacts from processing âœ…
- [x] Dynamic range is natural (not over-compressed) âœ…
- [x] SNR improved by >10dB âœ… (achieved +7.1dB on top of baseline)

### Audio Quality is "Excellent" When:
- [x] Sounds like professional podcast quality âœ… (Quality Score: 81.0)
- [x] Background noise barely perceptible âœ… (SNR: 28.5 dB)
- [x] Speaker voice is full and clear âœ…
- [ ] No echo or room reverb (Phase 4)
- [x] Consistent volume throughout âœ…

## ðŸš¨ Common Pitfalls to Avoid

1. **Don't change the test video URL** - We need consistency
2. **Don't remove existing functionality** - Add, don't replace
3. **Don't skip testing** - Every change must be measured
4. **Don't break the CLI interface** - Keep run.py working
5. **Don't ignore documentation** - Update logs immediately

## ðŸ“ž When to Ask for User Input

- When changing project scope or priorities
- When trade-offs significantly affect quality vs speed
- When adding major dependencies
- When refactoring core architecture

## ðŸ”§ Useful Commands

```bash
# Setup environment
cd audio-restorer
source venv/bin/activate

# Run main tool
python run.py "URL" --audio-only --quick

# Run tests
python -m pytest tests/ -v

# Analyze audio quality
python tests/analyze_quality.py output/audio.wav

# Compare two audio files
python tests/compare_audio.py file1.wav file2.wav

# View logs
cat ITERATION_LOG.md
cat ROADMAP.md
```

## ðŸŒ GitHub Integration

**Repository:** https://github.com/jcherranz/audio-restorer

For complete Git workflow, authentication, and commit guidelines, see: `docs/GITHUB_SETUP.md`

### Quick Reference

**ALWAYS commit when:**
- âœ… Completing a feature or iteration
- âœ… Fixing a bug
- âœ… Adding/updating tests
- âœ… Updating documentation
- âœ… Before ending a session

**NEVER commit:**
- âŒ Broken or incomplete code
- âŒ Files with failing tests
- âŒ Secrets or temporary files

**Commit message format:** `type: Brief description`
- `feat:` New feature | `fix:` Bug fix | `docs:` Documentation
- `test:` Tests | `refactor:` Code restructuring | `chore:` Maintenance

## Enhancer Interface Contract

All enhancers must follow this interface (defined in `src/enhancer_base.py`):

```python
from pathlib import Path
from src.enhancer_base import BaseEnhancer

class MyEnhancer(BaseEnhancer):
    def __init__(self,
                 noise_reduction_strength: float = 0.8,
                 use_gpu: bool = False,
                 verbose: bool = True):
        # Initialize enhancer
        pass

    @property
    def name(self) -> str:
        return "MyEnhancer"

    def enhance(self, input_path: Path, output_path: Path) -> Path:
        # Process audio
        # Return path to enhanced file
        return output_path
```

### Adding a New Enhancer

1. Create enhancer class in `src/` directory
2. Inherit from `BaseEnhancer` or follow the interface
3. Add to `_create_enhancer()` in `src/pipeline.py`
4. Add CLI option in `run.py` argument parser
5. Test with reference video
6. Update ITERATION_LOG.md with metrics

### Current Enhancers

| Name | File | Description |
|------|------|-------------|
| `simple` | audio_enhancer.py | ffmpeg filters only (fast) |
| `torch` | ml_enhancer.py | PyTorch spectral gating |
| `torch_advanced` | ml_enhancer.py | PyTorch + VAD |
| `deepfilter` | deepfilter_enhancer.py | Neural denoising (best quality) |


### Optional Post-Processing

| Name | File | Description |
|------|------|-------------|
| `--dereverb` | dereverb_enhancer.py | NARA-WPE de-reverberation (removes room echo) |

**Note:** De-reverberation is disabled by default. Use `--dereverb` flag for recordings with significant room echo. Best for files < 10 minutes due to CPU-intensive processing.

## Dependencies Status

### Currently Installed
- âœ… yt-dlp (YouTube downloading)
- âœ… ffmpeg (audio processing)
- âœ… numpy, soundfile (audio I/O)
- âœ… librosa (audio analysis)
- âœ… pydub (audio manipulation)
- âœ… noisereduce (spectral gating)

### To Install for Next Phase
- âœ… torch, torchaudio (for ML models) - INSTALLED
- âš ï¸ deepfilternet (had compatibility issues, using custom implementation)
- âœ… speechbrain (installed, available for Phase 3)

## ðŸŽ“ Reference Materials

### Audio Processing Concepts
- **Spectral Gating**: Removes noise by frequency analysis
- **Dynamic Range Compression**: Makes quiet parts louder, loud parts quieter
- **Normalization**: Adjusts overall volume to standard level
- **High/Low Pass Filters**: Remove unwanted frequency ranges

### Quality Metrics
- **SNR**: Signal-to-Noise Ratio in dB
- **LUFS**: Loudness units relative to full scale
- **RMS**: Root Mean Square (average volume)
- **Crest Factor**: Peak to RMS ratio (dynamic range indicator)

---

## Iteration Plan

### Phase 1: High-Impact Quality Improvements (Complete)
| # | Iteration | Status |
|---|-----------|--------|
| 0 | Infrastructure (docs, base class, quality gate) | Complete |
| 1 | Lowpass filter 8kHz -> 12kHz | Complete |
| 2 | Sample rate 16kHz -> 44.1kHz | Complete |
| 3 | DeepFilterNet neural denoising | Complete |
| 4 | Silero VAD neural speech detection | Complete |
| 5 | NARA-WPE de-reverberation | Complete |

### Phase 2: SOTA Upgrades (Complete)
| # | Iteration | Status |
|---|-----------|--------|
| 6 | SOTA metrics (DNSMOS, PESQ, STOI) | **Complete** |
| 7 | ~~Resemble Enhance~~ | **REMOVED** (dependency issues) |
| 8 | Comprehensive benchmark suite | **Complete** |
| 9 | Speaker diarization | **Complete** |
| 10 | Speaker isolation | **Complete** |
| 11 | Distance-robust enhancement | **Complete** |
| 12 | Per-speaker AGC | **Complete** |

### Phase 4: Audio Quality Refinement (In Progress)
| # | Iteration | Status |
|---|-----------|--------|
| 13 | scipy dependency + DeepFilterNet strength | **Complete** |
| 14 | Multi-video test suite | **Complete** |
| 15 | De-essing (sibilance control) | **Complete** |
| 16 | Hum removal (50/60Hz) | **Complete** |
| 17 | Click/pop removal | **Complete** |
| 18 | Comfort noise | **Complete** |
| 19 | Processing chain optimization | Pending |
| 20 | Quality tracking/DNSMOS target | Pending |

### Available Enhancers (Best to Basic)
1. `--enhancer deepfilter` - Neural network denoising (best quality)
2. `--enhancer torch_advanced` - PyTorch + Silero VAD (default)
3. `--enhancer torch` - PyTorch spectral gating
4. `--enhancer simple` - ffmpeg filters only (fastest)

### Optional Flags
- `--dereverb` - Add de-reverberation (removes room echo, CPU-intensive)
- `--diarize` - Perform speaker diarization (identifies speakers)
- `--isolate-speaker` - Isolate main speaker (removes audience/others)
- `--distance-robust` - Apply distance-robust enhancement (adaptive gain/EQ per speaker distance)
- `--speaker-agc` - Apply per-speaker automatic gain control (normalize each speaker's volume)
- `--deess` - Reduce harsh sibilant sounds (/s/, /sh/)
- `--remove-hum` - Remove power line hum (50/60Hz + harmonics)
- `--remove-clicks` - Remove clicks and pops (transient artifacts)
- `--comfort-noise` - Add comfort noise to silence (prevents dead air)

---

**Remember:** This is an AUDIO QUALITY project. Video is secondary.
Every iteration should make conference audio clearer and more intelligible.

**Last updated:** 2026-02-05 (Documentation review)
**Current Phase:** Phase 4 Complete - Ready for Phase 5 (Iterations 19-20)
**Best Quality Score:** 115.9/100 (DeepFilterNet - exceeded all targets)
**Available Refinements:** De-essing, hum removal, click removal, comfort noise
